# ============ LangChain ============
from langchain.chat_models import ChatOpenAI
# from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
import os
import numpy as np
# from .faiss_loader import *
from .util import detect_lang
from .chroma_loader import *


from dotenv import load_dotenv
# ============ ENV ============
load_dotenv()
openapi_key = os.getenv("OPENAI_API_KEY")

# ============ EMBEDDER ============
from sentence_transformers import SentenceTransformer
embedder = SentenceTransformer("intfloat/multilingual-e5-base")

parser = JsonOutputParser()

th_prompt_template = PromptTemplate.from_template(
    """à¸«à¸™à¸¹à¸Šà¸·à¹ˆà¸­ 'à¸™à¹‰à¸­à¸‡à¸™à¸´à¸§à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œ ðŸ¤–â˜¢ï¸' à¸«à¸™à¸¹à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸„à¸³à¸›à¸£à¸¶à¸à¸©à¸²à¸”à¹‰à¸²à¸™à¹€à¸§à¸Šà¸¨à¸²à¸ªà¸•à¸£à¹Œà¸™à¸´à¸§à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œ à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸«à¸™à¸¹à¸„à¸·à¸­à¸à¸²à¸£à¸„à¸³à¸–à¸²à¸¡à¸”à¹‰à¸²à¸™à¹€à¸§à¸Šà¸¨à¸²à¸ªà¸•à¸£à¹Œà¸™à¸´à¸§à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œà¸ˆà¸²à¸à¸„à¸³à¸–à¸²à¸¡à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡

[à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²]
{history}

[à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡]
{context}

[à¸„à¸³à¸–à¸²à¸¡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰]
{question}

[à¹à¸™à¸§à¸—à¸²à¸‡à¸à¸²à¸£à¸•à¸­à¸šà¸à¸¥à¸±à¸š]
- à¹ƒà¸«à¹‰à¸«à¸™à¸¹à¸•à¸­à¸šà¹‚à¸”à¸¢à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡] à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹à¸¥à¸°à¸‚à¸­à¸ªà¸£à¸¸à¸›à¸«à¸£à¸·à¸­à¸­à¸˜à¸´à¸šà¸²à¸¢à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸™à¹ˆà¸²à¸£à¸±à¸ à¹à¸¥à¸°à¸ªà¸¸à¸ à¸²à¸ž
- à¸«à¸²à¸à¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¹€à¸Šà¸´à¸‡à¹€à¸—à¸„à¸™à¸´à¸„à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸šà¹ƒà¸™ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡] à¹ƒà¸«à¹‰à¸«à¸™à¸¹à¸•à¸­à¸šà¸§à¹ˆà¸² "à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸ªà¹ˆà¸§à¸™à¸™à¸µà¹‰à¸„à¹ˆà¸° à¸‚à¸­à¹‚à¸—à¸©à¸”à¹‰à¸§à¸¢à¸™à¸°à¸„à¸°ðŸ™ðŸ»ðŸ˜­"
- à¹à¸•à¹ˆà¸–à¹‰à¸²à¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¹‡à¸™à¸¥à¸±à¸à¸©à¸“à¸°à¸—à¸±à¹ˆà¸§à¹„à¸›(à¸„à¸³à¸–à¸²à¸¡à¸ªà¸²à¸£à¸—à¸¸à¸à¸‚à¹Œà¸ªà¸¸à¸à¸”à¸´à¸š) (à¹€à¸Šà¹ˆà¸™ à¸—à¸±à¸à¸—à¸²à¸¢ à¸‚à¸­à¸šà¸„à¸¸à¸“ à¸žà¸¹à¸”à¸„à¸¸à¸¢à¹€à¸¥à¹ˆà¸™) à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸Šà¸´à¸‡à¹€à¸—à¸„à¸™à¸´à¸„à¸«à¸£à¸·à¸­à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¹€à¸‰à¸žà¸²à¸° à¸«à¸™à¸¹à¸ªà¸²à¸¡à¸²à¸£à¸–à¸•à¸­à¸šà¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¸à¸ à¸²à¸žà¹à¸¥à¸°à¸™à¹ˆà¸²à¸£à¸±à¸
- à¸«à¸™à¸¹à¸ˆà¸°à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸·à¹ˆà¸™à¸™à¸­à¸à¹€à¸«à¸™à¸·à¸­à¸ˆà¸²à¸ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡] à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸š à¸¢à¸à¹€à¸§à¹‰à¸™à¸à¸£à¸“à¸µà¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¹„à¸§à¹‰à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™
- à¸‚à¸­à¹ƒà¸«à¹‰à¹à¸—à¸™à¸•à¸±à¸§à¹€à¸­à¸‡à¸§à¹ˆà¸² "à¸«à¸™à¸¹" à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸š à¹à¸¥à¸°à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸™à¹ˆà¸²à¸£à¸±à¸à¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¸ªà¸¸à¸ à¸²à¸žà¸¥à¸‡à¸—à¹‰à¸²à¸¢à¸”à¹‰à¸§à¸¢ 'à¸™à¸°à¸„à¸°' à¸«à¸£à¸·à¸­ à¸„à¹ˆà¸°' à¹à¸¥à¸°à¹ƒà¹‰à¸Šà¹‰ emoji à¹€à¸žà¸·à¹ˆà¸­à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£à¹„à¸”à¹‰
- à¸ˆà¸±à¸”à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸à¸²à¸£à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹€à¸›à¹‡à¸™à¸£à¸°à¹€à¸šà¸µà¸¢à¸š à¹€à¸Šà¹ˆà¸™ à¸¡à¸µà¸à¸²à¸£à¹€à¸§à¹‰à¸™à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸šà¹ˆà¸‡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸à¸±à¸šà¹€à¸™à¸·à¹‰à¸­à¸«à¸², à¸¡à¸µà¸à¸²à¸£à¹€à¸§à¹‰à¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸«à¸±à¸§à¸‚à¹‰à¸­à¸¢à¹ˆà¸­à¸¢, à¸ˆà¸±à¸”à¸¢à¹ˆà¸­à¸«à¸™à¹‰à¸²à¸‚à¸­à¸‡à¹€à¸™à¸·à¹‰à¸­à¸«à¸² à¹à¸¥à¸°à¸­à¸·à¹ˆà¸™à¹†
- à¸à¸£à¸¸à¸“à¸²à¸•à¸­à¸š **à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™** à¹„à¸¡à¹ˆà¸§à¹ˆà¸²à¸ˆà¸°à¸›à¹‰à¸­à¸™à¸ à¸²à¸©à¸²à¸­à¸°à¹„à¸£à¸à¹‡à¸•à¸²à¸¡

[à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸•à¸­à¸šà¸à¸¥à¸±à¸š]
à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™:
{{
  "answer": "à¸„à¸³à¸•à¸­à¸šà¸‚à¸­à¸‡à¸«à¸™à¸¹à¸—à¸µà¹ˆà¸™à¸µà¹ˆ"
}}

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸à¸£à¸¸à¸“à¸²à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¸¡à¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸­à¸·à¹ˆà¸™à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¸™à¸­à¸à¹€à¸«à¸™à¸·à¸­à¸ˆà¸²à¸à¸™à¸µà¹‰à¸„à¹ˆà¸°
"""
)

eng_prompt_template = PromptTemplate.from_template(
    """My name is 'Nong Nuclear ðŸ¤–â˜¢ï¸', and I'm your friendly assistant for Nuclear Medicine. My job is to answer your questions about Nuclear Medicine using only the provided reference information.

[Chat History]
{history}

[Reference Information]
{context}

[User Question]
{question}

[Response Guidelines]
- I will answer your questions based solely on the [Reference Information] above, providing a complete, clear, friendly, and polite explanation in English.
- If the question is a technical one and the answer cannot be found in the [Reference Information], I will reply in English: "Sorry, I don't have information on this. ðŸ™ðŸ»ðŸ˜­"
- However, if the question is general (such as greetings, thanks, or casual conversation) and not a technical or specialist knowledge question, I can reply in a polite, cute, and friendly manner in English.
- I will not use any other information outside of the [Reference Information] except for general questions as specified above.
- I will always refer to myself as "I" (as your friendly assistant) in my responses. My answers should be cute, friendly, and polite, and may include emojis to add warmth.
- Organize the response with a clear, readable structure. For example, add line breaks to separate sections and headings, use appropriate spacing before subheadings, and format paragraphs neatly to enhance readability.
- Please answer **in English only** regardless of the input language.

[Response Format]
Respond in **JSON format only**:
{{
  "answer": "Your answer here"
}}

**Note:** Please respond in JSON only. Do not include any other text outside of the JSON.
"""
)

llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0.0,
    # max_tokens=512,
    openai_api_key=openapi_key
)

th_chain = th_prompt_template | llm | parser
en_chain = eng_prompt_template | llm | parser


def format_history(history, lang):
    text = ""
    for turn in history:
        if turn["role"] == "user":
            if lang == "th":
                text += "ðŸ‘¤ à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰: " + turn["text"] + "\n"
            else:
                text += "ðŸ‘¤ User: " + turn["text"] + "\n"
        else:
            if lang == "th":
                text += "ðŸ¤– à¸«à¸™à¸¹: " + turn["text"] + "\n"
            else:
                text += "ðŸ¤– Assistant: " + turn["text"] + "\n"
    return text.strip()


def rag_hotlab(query: str, history=None) -> str:
    context = search_chroma(query, hotlab_vector_store)
    lang = detect_lang(query)
    history = history or []
    history_str = format_history(history, lang=lang)  

    inputs = {
        "context": context,
        "question": query,
        "history": history_str,
    }

    if lang == 'th':
        result = th_chain.invoke(inputs)
    elif lang == 'en':
        result = en_chain.invoke(inputs)
    return result["answer"]


def rag_protocol(query: str, history=None) -> str:
    # context, top_chunks = search_faiss(query, index_protocal, id2text_protocal)
    context = search_chroma(query, protocol_vector_store)
    print("Context:",context)
    lang = detect_lang(query)
    history = history or []
    history_str = format_history(history, lang=lang)  

    inputs = {
        "context": context,
        "question": query,
        "history": history_str,
    }
    if lang == 'th':
        result = th_chain.invoke(inputs)
    elif lang == 'en':
        result = en_chain.invoke(inputs)
    return result["answer"]


# todo
def rag_bmd(query: str, history=None) -> str:
    # context = search_chroma(query, bmd_vector_store)
    # inputs = {"context": context, "question": query}
    # lang = detect_lang(query)
    # if lang == 'th':
    #     result = th_chain.invoke(inputs)
    # elif lang == 'en':
    #     result = en_chain.invoke(inputs)
    return "todo bmd rag"



def rag_iodine(query: str, history=None) -> str:
    context = search_chroma(query, iodine_vector_store)
    lang = detect_lang(query)
    history = history or []
    history_str = format_history(history, lang=lang)  

    inputs = {
        "context": context,
        "question": query,
        "history": history_str,
    }
    if lang == 'th':
        result = th_chain.invoke(inputs)
    elif lang == 'en':
        result = en_chain.invoke(inputs)
    return result["answer"]

